{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a101eaaafd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreuters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams,trigrams, download \n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathForWikiDataset = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\n",
    "wikiSentences = WikiCorpus(pathForWikiDataset).get_texts()\n",
    "download('punkt')\n",
    "download('reuters')\n",
    "reutersSentences  = reuters.sents()\n",
    "print(reutersSentences)\n",
    "print(wikiSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbabilities(sentenceModel):\n",
    "  for nextWord in sentenceModel:\n",
    "    nextWords = sentenceModel[nextWord]\n",
    "    total_Word_Count = float(sum(nextWords.values()))\n",
    "    for previousWord in nextWords:\n",
    "      nextWords[previousWord]/=total_Word_Count\n",
    "    \n",
    "def calculateSigleWordProbability(sentenceModel,wordCount):\n",
    "  for word in sentenceModel:\n",
    "    sentenceModel[word]/=wordCount\n",
    "\n",
    "def convertToLower(pa):\n",
    "  if type(pa)==str:\n",
    "    return pa.lower()\n",
    "  return pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentenceModel4 = defaultdict(lambda: set())\n",
    "sentenceModel5 = defaultdict(lambda: set())\n",
    "\n",
    "def calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,sentences):\n",
    "  wordCount = 0\n",
    "  for sentence in sentences:\n",
    "    #print(sentence)\n",
    "    for word in sentence:\n",
    "      wordCount+=1\n",
    "      sentenceModel1[word]+=1\n",
    "    for previousWord2,previousWord1,nextWord in trigrams(sentence,pad_right=True,pad_left=True):\n",
    "      previousWord1 = convertToLower(previousWord1)\n",
    "      previousWord2 = convertToLower(previousWord2)\n",
    "      # print(previousWord1)\n",
    "      # print(previousWord2)\n",
    "      nextWord = convertToLower(nextWord)\n",
    "      sentenceModel2[nextWord][previousWord1]+=1\n",
    "      sentenceModel3[nextWord][previousWord2]+=1\n",
    "      sentenceModel4[previousWord1].add(nextWord)\n",
    "      sentenceModel5[previousWord2].add(nextWord)\n",
    "\n",
    "  return wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceModel1 = defaultdict(lambda:0)\n",
    "sentenceModel2 = defaultdict(lambda: defaultdict(lambda:0))\n",
    "sentenceModel3 = defaultdict(lambda: defaultdict(lambda:0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,wikiSentences)\n",
    "print(wikiWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reutersWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,reutersSentences)\n",
    "print(reutersWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = wikiWordCount + reutersWordCount\n",
    "calculateSigleWordProbability(sentenceModel1,total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxProbabilityWords = []\n",
    "def makeWordSuggestionByTrigram(previousWord2,previousWord1):\n",
    "  for nextWord in sentenceModel4[previousWord1] and sentenceModel5[previousWord2]:\n",
    "    naiveBiasTrigramWeight = sentenceModel1[nextWord] * sentenceModel2[nextWord][previousWord1] * sentenceModel3[nextWord][previousWord2]\n",
    "    maxProbabilityWords.append((nextWord,naiveBiasTrigramWeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeWordSuggestionByTrigram('my','name')\n",
    "maxProbabilityWords.sort(key=lambda o:o[1],reverse=True)\n",
    "print(*maxProbabilityWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter: \")\n",
    "    if text == \"stop\":\n",
    "        break\n",
    "    try:\n",
    "            maxProbabilityWords = []\n",
    "            text = text.split(\" \")\n",
    "            makeWordSuggestionByTrigram(text[0],text[1])\n",
    "            maxProbabilityWords.sort(key=lambda o:o[1],reverse=True)\n",
    "            print(*maxProbabilityWords[:5])\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
